import time
import requests
import json
import urllib.parse
from datetime import datetime, timedelta
import os
 
def fetch_insights_range(account_id, access_token, start_date_str, end_date_str, pasta_saida="Megerd_Json"):
    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
    end_date = datetime.strptime(end_date_str, "%Y-%m-%d")

    while start_date <= end_date:
        # Define o final do m√™s (pode ser o pr√≥prio √∫ltimo dia do m√™s)
        next_month = start_date.replace(day=28) + timedelta(days=4)  # Vai para o pr√≥ximo m√™s
        end_of_month = next_month - timedelta(days=next_month.day)  # √öltimo dia do m√™s atual

        # Caso o final do m√™s ultrapasse a data final definida, ajusta
        if end_of_month > end_date:
            end_of_month = end_date

        # Formata as datas
        since = start_date.strftime("%Y-%m-%d")
        until = end_of_month.strftime("%Y-%m-%d")

        time_range = json.dumps({"since": since, "until": until})
        encoded_time_range = urllib.parse.quote(time_range)

        url = (
            f"https://graph.facebook.com/v22.0/act_{account_id}/insights"
            f"?time_increment=1&time_range={encoded_time_range}&level=ad"
            f"&fields=impressions,account_id,reach,spend,adset_id,adset_name,ad_id,ad_name,actions"
            f"&action_breakdowns=action_type&access_token={access_token}"
        )

        print(f"üîÑ Conta {account_id} ‚Äì Coletando de {since} at√© {until}...")

        todos_os_dados = []
        url_atual = url

        while url_atual:
            try:
                resposta = requests.get(url_atual)
                if resposta.status_code != 200:
                    print(f"‚ùå Erro {resposta.status_code} - {resposta.text}")
                    break

                dados = resposta.json()
                todos_os_dados.extend(dados.get("data", []))

                if "paging" in dados and "next" in dados["paging"]:
                    url_atual = dados["paging"]["next"]
                    time.sleep(0.2)
                else:
                    break
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao processar requisi√ß√£o: {e}")
                break

        # Cria√ß√£o da pasta, se n√£o existir
        os.makedirs(pasta_saida, exist_ok=True)

        if todos_os_dados:
            nome_arquivo = os.path.join(pasta_saida, f"{account_id}_insights_{since}_to_{until}.json")
            with open(nome_arquivo, "w", encoding="utf-8") as f:
                json.dump(todos_os_dados, f, indent=4, ensure_ascii=False)
            print(f"‚úÖ Salvo: {nome_arquivo}")
        else:
            print(f"‚ö†Ô∏è Sem dados para {account_id} de {since} at√© {until}.")

        # Avan√ßa para o pr√≥ximo m√™s
        start_date = end_of_month + timedelta(days=1)

if __name__ == "__main__":
    ACCESS_TOKEN = "EAANWRqx9Ex8BOZBEufWbayTjX3sy9StKOsGjZB6PBO8SFah2dVaK8orKcbLJnZCwWxymymHvzuHBlNUq9A1gRZAYLxF2Yid6DepOZBGeuAPC3qR3diDnpeU1B3Poj1NeNQMWwWqjfFahqaUzZCEzZAAGrub3dQIje1G4SR3Fhj3F5HuBlxDlAVVB4bvAiZB53zaempZBm3nMz"

    # Lista completa de contas de an√∫ncios
    lista_de_contas = [
        "185534306223063", "198313924760810", "196724701599490"
    ]

    # Define o intervalo desejado
    DATA_INICIO = "2025-02-06"
    DATA_FIM = "2025-05-06"

    for account_id in lista_de_contas:
        print(f"\nüü¶ Iniciando coleta para conta: {account_id}")
        fetch_insights_range(account_id, ACCESS_TOKEN, DATA_INICIO, DATA_FIM)
